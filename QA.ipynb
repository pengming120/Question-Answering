{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e916f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8671451",
   "metadata": {},
   "source": [
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395070bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import string\n",
    " \n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    " \n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    " \n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    " \n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    " \n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    " \n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    " \n",
    "def get_tokens(s):\n",
    "    if not s:\n",
    "        return []\n",
    "    return normalize_answer(s).split()\n",
    " \n",
    "def compute_exact(a_gold, a_pred):\n",
    "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
    " \n",
    "def compute_f1(a_gold, a_pred):\n",
    "    gold_toks = get_tokens(a_gold)\n",
    "    pred_toks = get_tokens(a_pred)\n",
    "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
    "    num_same = sum(common.values())\n",
    "    if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
    "        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
    "        return int(gold_toks == pred_toks)\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(pred_toks)\n",
    "    recall = 1.0 * num_same / len(gold_toks)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb7715",
   "metadata": {},
   "source": [
    "# utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de601b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # 四捨五入到最近的秒\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # 格式化為 hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def exactly_tokens(tokens):\n",
    "    # tokens:['a','b','##ccd']\n",
    "    temp = ''\n",
    "    for token in tokens:\n",
    "        if token[:2]=='##':\n",
    "            temp += token[2:]\n",
    "        else:\n",
    "            temp += ' '+token\n",
    "    return temp[1:]\n",
    "\n",
    "def get_predAns(input_vector,start,end):\n",
    "    predAns = []\n",
    "    for i,vector in enumerate(input_vector):\n",
    "        pred_id = vector[start[i]:end[i]+1]\n",
    "        tokens = tokenizer.convert_ids_to_tokens(pred_id)    # ['a','b','##ccd']\n",
    "        predAns.append(exactly_tokens(tokens))\n",
    "    # return predAns[ans1,ans2,...,ansn]\n",
    "    return predAns\n",
    "\n",
    "def get_metrics(predAns,ans):\n",
    "    f1_count = 0\n",
    "    EM_count = 0\n",
    "    assert len(predAns)==len(ans)\n",
    "    for i,pred in enumerate(predAns):\n",
    "        f1_count += compute_f1(ans[i],pred)\n",
    "        EM_count += compute_exact(ans[i],pred)\n",
    "    return f1_count, EM_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f150612",
   "metadata": {},
   "source": [
    "# process raw data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6839ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paragraph_QA(data):\n",
    "    paragraph = []\n",
    "    QA = []\n",
    "    for line in data:\n",
    "        snippets = []\n",
    "        while True:\n",
    "            try:\n",
    "                idx = line.index('</s>')\n",
    "            except:\n",
    "                break\n",
    "            snippet = line[:idx+4]\n",
    "            line = line[len(snippet):]\n",
    "            snippets.append(snippet.strip()[3:-4].strip())\n",
    "        # get QA\n",
    "        idx_1 = line.index('|||')    # first '|||' index\n",
    "        idx_2 = line.index('|||',idx_1+3)    # second '|||' index\n",
    "        Q = line[idx_1+3:idx_2].strip()\n",
    "        A = line[idx_2+3:].strip()\n",
    "        QA.append([Q,A])\n",
    "        paragraph.append(snippets)\n",
    "        assert len(paragraph)==len(QA)\n",
    "    return paragraph,QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43fb4fc",
   "metadata": {},
   "source": [
    "# get model input data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5177b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_end_pos(a,b):\n",
    "    flag=False\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(b)):\n",
    "            if(b[j] == a[i+j]):\n",
    "                flag=True\n",
    "                start=i\n",
    "            else:\n",
    "                flag=False\n",
    "                start=0\n",
    "                end=0\n",
    "                break\n",
    "        if flag==True:\n",
    "            end=i+j\n",
    "            break\n",
    "    return start,end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97861778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只取前面的384 token\n",
    "bert_input_len = 384\n",
    "def get_data(mode,QA,paragraph,tokenizer):\n",
    "    input_vector = []\n",
    "    att_mask = []\n",
    "    segment_ids = []\n",
    "    start_pos=[]\n",
    "    end_pos=[]\n",
    "    ans = []\n",
    "    for i,doc in enumerate(paragraph):\n",
    "        count=0\n",
    "        while count<len(doc):\n",
    "            if count==0:\n",
    "                # return a list: [101,...,102](101為cls,102為sep)，若return_tensors = 'pt'\n",
    "                # 則return tensor([[101,...,102]])\n",
    "                ls1 = tokenizer.encode(QA[i][0], add_special_tokens=True)\n",
    "                ls2 = tokenizer.encode(doc[count]+'.', add_special_tokens=False) \n",
    "                input_id = ls1+ls2\n",
    "            else:\n",
    "                ls1 = tokenizer.encode(doc[count]+'.',add_special_tokens=False)\n",
    "                if len(input_id+ls1)>(bert_input_len-1):break\n",
    "                else:input_id += ls1\n",
    "            count+=1\n",
    "        input_id += [102]\n",
    "        num_pad = bert_input_len-len(input_id)\n",
    "        input_id += [0]*num_pad\n",
    "        input_vector.append(torch.Tensor(input_id).type(torch.LongTensor))\n",
    "        \n",
    "        # attention mask\n",
    "        mask = [1]*(bert_input_len-num_pad)+[0]*num_pad\n",
    "        att_mask.append(torch.Tensor(mask).type(torch.FloatTensor))\n",
    "        \n",
    "        # segment_ids\n",
    "        sep_index = input_id.index(tokenizer.sep_token_id)\n",
    "        num_seg_a = sep_index + 1\n",
    "        num_seg_b = len(input_id) - num_seg_a\n",
    "        temp = [0]*num_seg_a + [1]*num_seg_b\n",
    "        segment_ids.append(torch.Tensor(temp).type(torch.LongTensor))\n",
    "        \n",
    "        # start end position\n",
    "        if mode !='test':\n",
    "            # get text_ans\n",
    "            ans_token = tokenizer.tokenize(QA[i][1])\n",
    "            a = input_id\n",
    "            b = tokenizer.convert_tokens_to_ids(ans_token)\n",
    "            start,end = start_end_pos(a,b)\n",
    "            if start==0 and end==0:ans.append(exactly_tokens('[CLS]'))  \n",
    "            else:ans.append(exactly_tokens(ans_token))\n",
    "            start_pos.append(start)\n",
    "            end_pos.append(end)\n",
    "    start_pos = torch.Tensor(start_pos).type(torch.LongTensor)\n",
    "    end_pos = torch.Tensor(end_pos).type(torch.LongTensor)\n",
    "    \n",
    "    print('done!!!')\n",
    "    if mode != 'test':\n",
    "        assert len(input_vector) == len(segment_ids) == len(att_mask) == len(start_pos) == len(end_pos)\n",
    "        return input_vector,att_mask,segment_ids,start_pos,end_pos,ans\n",
    "    else:\n",
    "        assert len(input_vector) == len(segment_ids) == len(att_mask)\n",
    "        return input_vector,att_mask,segment_ids\n",
    "# input_vector:[tensor([1,2,3,...,55,6]),...,tensor([1,26,33,...,54,22])]\n",
    "# att_mask:[tensor([1,1,1,...,0,0],...,tensor([1,1,1,...,1,0])]\n",
    "# start_pos:tensor([33,54,87,1,2,...,333])\n",
    "# end_pos:tensor([33,54,87,1,2,...,333])\n",
    "# segment_ids:[tensor([0,0,0,...,1,1,1,1],...,tensor([0,0,0,...,1,1,1,1])]\n",
    "# ans: [ans1,ans2,...,ansn]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2032a0f8",
   "metadata": {},
   "source": [
    "# pretrain model,output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067a7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "class QAModelOutput:\n",
    "    def __init__(self,loss,start_logits,end_logits):\n",
    "        self.loss=loss\n",
    "        self.start_logits=start_logits\n",
    "        self.end_logits=end_logits\n",
    "\n",
    "class CustomeModel(nn.Module):\n",
    "    def __init__(self,bert_model):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.qa_outputs = nn.Linear(1024, 2)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        token_type_ids=None,\n",
    "        attention_mask=None,\n",
    "        output_hidden_states=None,\n",
    "        start_positions=None,\n",
    "        end_positions=None,\n",
    "    ):\n",
    "        \n",
    "        outputs = self.bert(input_ids=input_ids,token_type_ids=token_type_ids,attention_mask=attention_mask,output_hidden_states=output_hidden_states)\n",
    "        seq_out = outputs.last_hidden_state\n",
    "        logits = self.qa_outputs(seq_out)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1).contiguous()\n",
    "        end_logits = end_logits.squeeze(-1).contiguous()\n",
    "\n",
    "        total_loss = None\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "\n",
    "        return QAModelOutput(\n",
    "            loss=total_loss,\n",
    "            start_logits=start_logits,\n",
    "            end_logits=end_logits\n",
    "        )\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = CustomeModel(bert).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05c01c",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89072cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目前只有train, val\n",
    "from torch.utils.data import Dataset\n",
    "class QA_Dataset(Dataset):\n",
    "    '''Dataset for loading and preprocessing'''\n",
    "    def __init__(self, mode,x_vectors,att_mask,segment_ids,start=None, end=None,ans=None):\n",
    "        self.mode = mode\n",
    "        self.x_vectors = x_vectors\n",
    "        self.att_mask = att_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.ans = ans\n",
    "    def __len__(self):\n",
    "        return len(self.x_vectors)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode=='train' or self.mode=='val':\n",
    "            return self.x_vectors[idx], self.att_mask[idx], self.segment_ids[idx],self.start[idx], self.end[idx], self.ans[idx]\n",
    "        else:\n",
    "            return self.x_vectors[idx], self.att_mask[idx], self.segment_ids[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b1b5a3",
   "metadata": {},
   "source": [
    "# get train,val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65052b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train.txt','r') as f1:\n",
    "    data1 = f1.readlines()\n",
    "with open('./val.txt','r') as f2:\n",
    "    data2 = f2.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141aba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# train data\n",
    "train_paragraph,train_QA = get_paragraph_QA(data1)\n",
    "train_vector,train_att_mask,train_segment_ids,train_start_pos,train_end_pos,train_ans = get_data('train',train_QA,train_paragraph,tokenizer)\n",
    "\n",
    "batch_size = 3\n",
    "train_dataset = QA_Dataset(mode='train', x_vectors=train_vector, att_mask=train_att_mask,segment_ids=train_segment_ids,start=train_start_pos, end=train_end_pos,ans=train_ans)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32995a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val data\n",
    "val_paragraph,val_QA = get_paragraph_QA(data2)\n",
    "val_vector,val_att_mask,val_segment_ids,val_start_pos,val_end_pos,val_ans = get_data('val',val_QA,val_paragraph,tokenizer)\n",
    "\n",
    "val_dataset = QA_Dataset(mode='val', x_vectors=val_vector, att_mask=val_att_mask,segment_ids=val_segment_ids,start=val_start_pos, end=val_end_pos,ans=val_ans)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4d3b36",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a020c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "import os\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n",
    "                )\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# 訓練 epochs。 BERT 作者建議在 2 和 4 之間，設大了容易過擬合 \n",
    "epochs = 5\n",
    "\n",
    "# 總的訓練樣本數\n",
    "total_steps = len(train_loader) * epochs\n",
    "\n",
    "# 建立學習率排程器\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# 設定隨機種子值，以確保輸出是確定的\n",
    "'''\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "'''\n",
    "# 儲存訓練和評估的 loss、準確率、訓練時長等統計指標, to txt file\n",
    "f = open('./training_state.txt','w')\n",
    "\n",
    "# 統計整個訓練時長\n",
    "total_t0 = time.time()\n",
    "\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    # 將模型設定為訓練模式。這裡並不是呼叫訓練介面的意思\n",
    "    # dropout、batchnorm 層在訓練和測試模式下的表現是不同的 (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "   \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 統計單次 epoch 的訓練時間\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 重置每次 epoch 的訓練總 loss\n",
    "    total_train_loss = 0\n",
    "    f1_count = 0\n",
    "    EM_count = 0\n",
    "    \n",
    "    # 訓練集小批量迭代\n",
    "    for step,batch in enumerate(train_loader):\n",
    "        \n",
    "        # input_vector: tensor([[...],...,[...]]),shape:B*bert input len\n",
    "        # att_mask: tensor([[...],...,[...]]),shape:B*bert input len\n",
    "        # segment_ids: tensor([[...],...,[...]]),shape:B*bert input len\n",
    "        # start,end: tensor([...]),shape:B,\n",
    "        input_vector, att_mask, segment_ids, start, end, ans = batch\n",
    "        \n",
    "        # 每經過1000次迭代，就輸出進度資訊\n",
    "        if step % 3000 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_loader), elapsed))\n",
    "\n",
    "        # 準備輸入資料，並將其拷貝到 gpu 中\n",
    "        input_vector = input_vector.to(device)\n",
    "        att_mask = att_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        start = start.to(device)\n",
    "        end = end.to(device)\n",
    "        \n",
    "        # 每次計算梯度前，都需要將梯度清 0，因為 pytorch 的梯度是累加的\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # forward\n",
    "        output = model(input_ids=input_vector,token_type_ids=segment_ids,attention_mask=att_mask,output_hidden_states=True,start_positions=start,end_positions=end)\n",
    "\n",
    "        # Choose the most probable start position / end position \n",
    "        start_index = torch.argmax(output.start_logits, dim=1)\n",
    "        end_index = torch.argmax(output.end_logits, dim=1)\n",
    "        \n",
    "        # get prediction index to vector,and caculate metrics, return predAns:batch\n",
    "        predAns = get_predAns(input_vector,start_index,end_index)\n",
    "        f1_score, EM = get_metrics(predAns,ans)\n",
    "        f1_count += f1_score\n",
    "        EM_count += EM\n",
    "        if step % 3000 == 0 and not step == 0:\n",
    "            print('train pred ans: ',predAns)\n",
    "            print('train exact ans: ',ans)\n",
    "        \n",
    "        # 累加 loss\n",
    "        total_train_loss += output.loss.item()\n",
    "\n",
    "        # backward\n",
    "        output.loss.backward()\n",
    "\n",
    "        # 梯度裁剪，避免出現梯度爆炸情況\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # update learning\n",
    "        scheduler.step()\n",
    "\n",
    "    # caculate average training loss,f1,em\n",
    "    train_avg_loss = total_train_loss/len(train_loader)  \n",
    "    train_avg_f1 = f1_count/len(train_dataset)\n",
    "    train_avg_EM = EM_count/len(train_dataset)\n",
    "    \n",
    "    # one epoch 的訓練時長\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    \n",
    "    # print training loss,training (f1,em),training time\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.4f}\".format(train_avg_loss))\n",
    "    print(\"  Average training f1: {0:.4f},EM: {0:.4f}\".format(train_avg_f1,train_avg_EM))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # 完成一次 epoch 訓練後，就對該模型的效能進行驗證\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 設定模型為評估模式\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_loss = 0\n",
    "    max_f1 = 0\n",
    "    max_EM = 0\n",
    "    f1_count = 0\n",
    "    EM_count = 0\n",
    "    \n",
    "    # Evaluate data for one epoch\n",
    "    for step,batch in enumerate(val_loader):\n",
    "        \n",
    "        # input_vector: tensor([[...],...,[...]]),shape:B*bert input len\n",
    "        # att_mask: tensor([[...],...,[...]]),shape:B*bert input len\n",
    "        # segment_ids: tensor([[...],...,[...]]),shape:B*bert input len\n",
    "        # start,end: tensor([...]),shape:B,\n",
    "        input_vector, att_mask, segment_ids, start, end, ans = batch\n",
    "        \n",
    "        # 將輸入資料載入到 gpu 中\n",
    "        input_vector = input_vector.to(device)\n",
    "        att_mask = att_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        start = start.to(device)\n",
    "        end = end.to(device)\n",
    "        \n",
    "        # 評估的時候不需要更新引數、計算梯度\n",
    "        with torch.no_grad():        \n",
    "            output = model(input_ids=input_vector,token_type_ids=segment_ids, attention_mask=att_mask,output_hidden_states=True,start_positions=start,end_positions=end)\n",
    "            \n",
    "        # Choose the most probable start position / end position\n",
    "        start_index = torch.argmax(output.start_logits, dim=1)\n",
    "        end_index = torch.argmax(output.end_logits, dim=1)\n",
    "        \n",
    "        # get prediction index to vector,and caculate metrics, return predAns:batch,len\n",
    "        predAns = get_predAns(input_vector,start_index,end_index)\n",
    "        f1_score, EM = get_metrics(predAns,ans)\n",
    "        f1_count += f1_score\n",
    "        EM_count += EM\n",
    "        if step % 1000 == 0 and not step == 0:\n",
    "            print('val pred ans: ',predAns)\n",
    "            print('val exact ans: ',ans)\n",
    "        \n",
    "        # 累加 loss\n",
    "        total_eval_loss += output.loss.item()\n",
    "\n",
    "    # caculate average val loss,f1,em\n",
    "    val_avg_loss = total_eval_loss / len(val_loader)\n",
    "    val_avg_f1 = f1_count/len(val_dataset)\n",
    "    val_avg_EM = EM_count/len(val_dataset)\n",
    "    \n",
    "    # 統計本次評估的時長\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    # save best val model\n",
    "    if val_avg_f1>max_f1:\n",
    "        max_f1=val_avg_f1\n",
    "        torch.save({'Bert_model':model.state_dict()},'./val_best_model.pth')\n",
    "        print('save new model with higher f1: {}\\n'.format(val_avg_f1))\n",
    "        \n",
    "    print(\"  Validation Loss: {0:.4f}\".format(val_avg_loss))\n",
    "    print(\"  Validation f1: {0:.4f},EM: {0:.4f}\".format(val_avg_f1,val_avg_EM))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # 記錄本次 epoch 的所有統計資訊\n",
    "    training_state = {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Train Loss': train_avg_loss,\n",
    "            'Train f1': train_avg_f1,\n",
    "            'Train EM': train_avg_EM,\n",
    "            'Val Loss': val_avg_loss,\n",
    "            'Val f1': val_avg_f1,\n",
    "            'Val EM': val_avg_EM,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    f.write(str(training_state)+'\\n')\n",
    "f.close()\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd7d1e",
   "metadata": {},
   "source": [
    "# Inference test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf079c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test.txt','r') as f3:\n",
    "    data3 = f3.readlines()\n",
    "\n",
    "# test data\n",
    "test_paragraph,test_QA = get_paragraph_QA(data3)\n",
    "test_input_vector,test_att_mask,test_segment_ids = get_data('test',test_QA,test_paragraph,tokenizer)\n",
    "\n",
    "test_dataset = QA_Dataset(mode='test', x_vectors=test_input_vector, att_mask=test_att_mask, segment_ids=test_segment_ids)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dac58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./val_best_model.pth')\n",
    "model.load_state_dict(checkpoint['Bert_model'])\n",
    "model = model.to(device)\n",
    "f = open('./result.txt','w')\n",
    "lines = []\n",
    "for i,batch in enumerate(test_loader):\n",
    "    print(i)\n",
    "    input_vector,att_mask,segment_ids = batch\n",
    "    # to device\n",
    "    input_vector = input_vector.to(device)\n",
    "    att_mask = att_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    \n",
    "    # 評估的時候不需要更新引數、計算梯度\n",
    "    with torch.no_grad():        \n",
    "        output = model(input_ids=input_vector,token_type_ids=segment_ids,attention_mask=att_mask)\n",
    "    \n",
    "    # Choose the most probable start position / end position\n",
    "    start_index = torch.argmax(output.start_logits, dim=1)\n",
    "    end_index = torch.argmax(output.end_logits, dim=1)\n",
    "    predAns = get_predAns(input_vector,start_index,end_index)   \n",
    "    \n",
    "    lines.append(test_QA[i][0]+' ||| '+predAns[0]+'\\n')\n",
    "f.writelines(lines)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
